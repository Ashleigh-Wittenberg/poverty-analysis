{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 28\u001b[0m\n\u001b[0;32m     18\u001b[0m percentage_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18-24<hs_grad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18-24_hs_grad/equiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18-24_some_college/associate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m18-24_bachelor/higher\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+<9th_grade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+_9th-12th_grade_nongrad\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+_hs_grad/equiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+_some_college\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m25+_associate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m25+_bachelor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+<hs_grad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+_hs_grad/equiv.1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+_some_college/associate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m25+_bachelor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25+>bachelor.1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m percentage_columns:\n\u001b[1;32m---> 28\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Convert columns with commas to numeric types\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Handles the 'O' data types\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m2\u001b[39m:]:\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m is_categorical_dtype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\trist\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    232\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Attempting to process data types first to get correct format\n",
    "# Nested the target CSV files into another \"resources\"\n",
    "folder_path = 'resources'\n",
    "\n",
    "# List to store processed data\n",
    "preprocessed_data = []\n",
    "\n",
    "# Grab each CSV and read in, manually edit format and data type by column\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(folder_path, file_name))\n",
    "\n",
    "        # Convert percentage columns to decimal numbers\n",
    "        percentage_columns = ['18-24<hs_grad', '18-24_hs_grad/equiv', '18-24_some_college/associate',\n",
    "                              '18-24_bachelor/higher', '25+<9th_grade', '25+_9th-12th_grade_nongrad',\n",
    "                              '25+_hs_grad/equiv', '25+_some_college', \"25+_associate's\", \"25+_bachelor's\",\n",
    "                              '25+>bachelor', '25-34_hs_grad/higher', '25-34_bachelor/higher',\n",
    "                              '35-44_hs_grad/higher', '35-44_bachelor/higher', '45-64_hs_grad/higher',\n",
    "                              '45-64_bachelor/higher', '65+_hs_grad/higher', '65+_bachelor/higher',\n",
    "                              '25+<hs_grad', '25+_hs_grad/equiv.1', '25+_some_college/associate',\n",
    "                              \"25+_bachelor's.1\", '25+>bachelor.1']\n",
    "\n",
    "        for col in percentage_columns:\n",
    "            df[col] = df[col].str.rstrip('%').str.replace(',', '').astype(float) / 100\n",
    "\n",
    "        # Convert columns with commas to numeric types\n",
    "        # Handles the 'O' data types\n",
    "        for col in df.columns[2:]:\n",
    "            if df[col].dtype == 'O':  \n",
    "                df[col] = df[col].str.replace(',', '').astype(float)\n",
    "\n",
    "        # Append the preprocessed DataFrame to the list\n",
    "        preprocessed_data.append(df)\n",
    "\n",
    "# Check each to see if this method works\n",
    "for i, df in enumerate(preprocessed_data):\n",
    "    print(f\"DataFrame {i+1}:\")\n",
    "    print(df.head())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 'District of Columbia' not found in 'states' table.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "State ID not found for 'District of Columbia'.\n",
      "Database created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sqlite3\n",
    "\n",
    "# Nested path that contains first batch of CSVs\n",
    "folder_path = 'resources'\n",
    "\n",
    "# DB Creation:\n",
    "db_filename = 'Poverty_DB_test02.db'\n",
    "conn = sqlite3.connect(db_filename)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Initial table to handle keys by taking just state names and assigning an ID for referencing \n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS states (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    state TEXT UNIQUE\n",
    "                )''')\n",
    "\n",
    "# Function to preprocess the CSV files and create tables \n",
    "# Using REAL data types to include any % values, floats or ints. These CSVs have a variety of numerics, and 2014 - 2015 has a shift\n",
    "# in data for certain columns\n",
    "def process_csv(file_path, table_name):\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Write schema for current table\n",
    "    schema = ['id INTEGER PRIMARY KEY', 'state_id INTEGER', 'year INTEGER']\n",
    "    for col in df.columns[2:]:\n",
    "        schema.append(f'\"{col}\" REAL')\n",
    "\n",
    "    # Create Table\n",
    "    cursor.execute(f'''CREATE TABLE IF NOT EXISTS {table_name} ({\", \".join(schema)}, FOREIGN KEY (state_id) REFERENCES states(id))''')\n",
    "\n",
    "    # Each instance of a state stored\n",
    "    # Some states have a space after\n",
    "    states = df['state'].unique()\n",
    "    for state in states:\n",
    "        # Remove whitespace from states\n",
    "        state = state.strip()\n",
    "        cursor.execute('''INSERT OR IGNORE INTO states (state) VALUES (?)''', (state,))\n",
    "\n",
    "    # Insert data into current table and check for mismatch\n",
    "    for index, row in df.iterrows():\n",
    "        state_id = cursor.execute('''SELECT id FROM states WHERE state = ?''', (row['state'].strip(),)).fetchone()\n",
    "        if state_id:\n",
    "            state_id = state_id[0]  # Check if state_id is not None\n",
    "            cursor.execute(f'''INSERT INTO {table_name} (state_id, year, '''\n",
    "                           + ', '.join([f'\"{col}\"' for col in df.columns[2:]]) +\n",
    "                           ''') VALUES ('''\n",
    "                           + ', '.join(['?' for _ in range(len(df.columns))]) +\n",
    "                           ''')''', [state_id] + row.tolist()[1:])\n",
    "        else:\n",
    "            print(f\"State ID not found for '{row['state']}'.\")\n",
    "\n",
    "# Loop through each CSV file and grab year for table name\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        \n",
    "        year = file_name.split('_')[2].split('.')[0]\n",
    "\n",
    "        # Skip 2020 (no data)\n",
    "        if year == '2020':\n",
    "            continue\n",
    "\n",
    "        # Write schema for current table\n",
    "        table_name = f'data_{year}'\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Process the CSV file and create table in the database\n",
    "        process_csv(file_path, table_name)\n",
    "\n",
    "# Commit initial CSV batch to DB\n",
    "conn.commit()\n",
    "\n",
    "# Now, adding the new API data as a table - this file is in directory with notebook, not in previous batch\n",
    "new_csv_file = 'API_Poverty.csv'  \n",
    "new_df = pd.read_csv(new_csv_file)\n",
    "\n",
    "# Create table schema\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS API_Data (\n",
    "                    id INTEGER PRIMARY KEY,\n",
    "                    state_id INTEGER,\n",
    "                    median_h_income INTEGER,\n",
    "                    poverty_rate REAL,\n",
    "                    poverty_count INTEGER,\n",
    "                    year INTEGER,\n",
    "                    FOREIGN KEY (state_id) REFERENCES states(id)\n",
    "                )''')\n",
    "\n",
    "# Same process for key state table\n",
    "# Note \"District of Columbia\" not in original batch of CSVs so this is removed, shown in output cell\n",
    "state_ids = {}\n",
    "for state in new_df['state'].unique():\n",
    "    # Remove trailing whitespace from state names\n",
    "    state = state.strip()\n",
    "    state_id = cursor.execute('''SELECT id FROM states WHERE state = ?''', (state,)).fetchone()\n",
    "    if state_id:\n",
    "        state_id = state_id[0]  # Check if state_id is not None\n",
    "        state_ids[state] = state_id\n",
    "    else:\n",
    "        print(f\"State '{state}' not found in 'states' table.\")\n",
    "\n",
    "# Load table\n",
    "for index, row in new_df.iterrows():\n",
    "    state_id = state_ids.get(row['state'])\n",
    "    if state_id is not None:\n",
    "        cursor.execute('''INSERT INTO API_Data (state_id, median_h_income, poverty_rate, poverty_count, year)\n",
    "                          VALUES (?, ?, ?, ?, ?)''', (state_id, row['median_h_income'], row['poverty_rate'], row['poverty_count'], row['year']))\n",
    "    else:\n",
    "        print(f\"State ID not found for '{row['state']}'.\")\n",
    "\n",
    "# Commit & close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Database created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
